{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "e0bf8629",
            "metadata": {},
            "source": [
                "This notebook reads the generated base_graph, base_network, and od_base_graph; loops for each hazard map in the folder and runs the od analysis. This happens N times (N= # of flood maps)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e67d001f",
            "metadata": {},
            "outputs": [],
            "source": [
                "import geopandas as gpd\n",
                "import pandas as pd\n",
                "from pathlib import Path\n",
                "import pickle\n",
                "from ra2ce.network.network_config_data.enums.aggregate_wl_enum import AggregateWlEnum\n",
                "from ra2ce.network.network_config_data.enums.source_enum import SourceEnum\n",
                "from ra2ce.network.network_config_data.network_config_data import (\n",
                "    HazardSection,\n",
                "    NetworkConfigData,\n",
                "    NetworkSection,\n",
                "    OriginsDestinationsSection\n",
                ")\n",
                "from ra2ce.configuration.config_wrapper import ConfigWrapper\n",
                "from ra2ce.analysis.analysis_config_wrapper import AnalysisConfigWrapper\n",
                "from ra2ce.analysis.analysis_config_data.analysis_config_data import AnalysisConfigData\n",
                "from ra2ce.ra2ce_handler import Ra2ceHandler\n",
                "from ra2ce.analysis.analysis_config_data.analysis_config_data import AnalysisSectionBase, AnalysisSectionLosses, ProjectSection\n",
                "from ra2ce.analysis.analysis_config_data.enums.analysis_damages_enum import AnalysisDamagesEnum\n",
                "from ra2ce.analysis.analysis_config_data.enums.analysis_losses_enum import AnalysisLossesEnum\n",
                "from ra2ce.analysis.analysis_config_data.enums.damage_curve_enum import DamageCurveEnum\n",
                "from ra2ce.analysis.analysis_config_data.enums.event_type_enum import EventTypeEnum\n",
                "from ra2ce.analysis.analysis_config_data.enums.weighing_enum import WeighingEnum\n",
                "from ra2ce.analysis.losses.multi_link_origin_closest_destination import MultiLinkOriginClosestDestination\n",
                "from ra2ce.network.network_config_data.enums.road_type_enum import RoadTypeEnum\n",
                "from ra2ce.network.network_config_wrapper import NetworkConfigWrapper\n",
                "from ra2ce.network.graph_files.graph_files_collection import GraphFilesCollection\n",
                "from ra2ce.network.graph_files.graph_file import GraphFile\n",
                "from ra2ce.network.graph_files.network_file import NetworkFile\n",
                "from ra2ce.network.hazard.hazard_names import HazardNames"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1c3e50cb",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Functions\n",
                "\n",
                "def get_all_files(directory: str) -> list[Path]:\n",
                "    \"\"\"\n",
                "    Get all file names in the specified directory.\n",
                "\n",
                "    Args:\n",
                "        directory (str): The path to the directory.\n",
                "\n",
                "    Returns:\n",
                "        List[str]: A list of file names in the directory.\n",
                "    \"\"\"\n",
                "    p = Path(directory)\n",
                "    return [file for file in p.iterdir() if file.is_file()]\n",
                "\n",
                "def read_pickle(file_path: str):\n",
                "    \"\"\"\n",
                "    Read a pickle file.\n",
                "\n",
                "    Args:\n",
                "        file_path (str): The path to the pickle file.\n",
                "\n",
                "    Returns:\n",
                "        The object stored in the pickle file.\n",
                "    \"\"\"\n",
                "    with open(file_path, 'rb') as file:\n",
                "        data = pickle.load(file)\n",
                "    return data\n",
                "\n",
                "def read_gpkg_to_gdf(file_path: str, layer: str = None) -> gpd.GeoDataFrame:\n",
                "    \"\"\"\n",
                "    Read a GeoPackage file into a GeoDataFrame.\n",
                "\n",
                "    Args:\n",
                "        file_path (str): The path to the GeoPackage file.\n",
                "        layer (str, optional): The specific layer to read from the GeoPackage. If None, reads the default layer.\n",
                "\n",
                "    Returns:\n",
                "        gpd.GeoDataFrame: The GeoDataFrame created from the GeoPackage file.\n",
                "    \"\"\"\n",
                "    # Read the geopackage file into a GeoDataFrame\n",
                "    gdf = gpd.read_file(file_path, layer=layer)\n",
                "    \n",
                "    return gdf"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "737dfbc2",
            "metadata": {},
            "outputs": [],
            "source": [
                "_root_dir = Path(r'.\\exposure_and_od_analysis')\n",
                "_static_path = _root_dir.joinpath(\"static\")\n",
                "_output_path = _root_dir.joinpath(\"output\")\n",
                "_base_graph_dir = _static_path.joinpath('output_graph')\n",
                "\n",
                "hazard_files = get_all_files(_static_path / \"hazard\")\n",
                "hazard_crs = \"EPSG:32736\" # for the hackathon case => \"EPSG:4326\" "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1f974eed",
            "metadata": {},
            "outputs": [],
            "source": [
                "for hazard_file in hazard_files:\n",
                "    # Make the NetworkConfigData\n",
                "    _hazard_section = HazardSection(\n",
                "        hazard_map=[hazard_file],\n",
                "        hazard_id=None,\n",
                "        hazard_field_name=\"waterdepth\",\n",
                "        aggregate_wl=AggregateWlEnum.MAX,\n",
                "        hazard_crs=hazard_crs,\n",
                "        overlay_segmented_network = False\n",
                "    )\n",
                "\n",
                "    _origin_destination_section = OriginsDestinationsSection(\n",
                "        origins=_static_path.joinpath(\"network\", \"origins.shp\"),\n",
                "        destinations=_static_path.joinpath(\"network\", \"destinations.shp\"),\n",
                "        origins_names=\"A\",\n",
                "        destinations_names=\"B\",\n",
                "        id_name_origin_destination=\"OBJECTID\",\n",
                "        origin_count=\"POPULATION\",\n",
                "        origin_out_fraction=1,\n",
                "        category=\"category\",\n",
                "    )\n",
                "    \n",
                "    _network_config_data = NetworkConfigData(\n",
                "        root_path=_root_dir,\n",
                "        static_path=_static_path,\n",
                "        output_path=_output_path,\n",
                "        hazard=_hazard_section,\n",
                "        origins_destinations=_origin_destination_section,\n",
                "    )    \n",
                "    _network_config_data.network.save_gpkg = True\n",
                "\n",
                "    # Make the AnalysisConfigData\n",
                "    _analysis_section = AnalysisSectionLosses(\n",
                "        name='origin_closest_destination',\n",
                "        analysis=AnalysisLossesEnum.MULTI_LINK_ORIGIN_CLOSEST_DESTINATION,\n",
                "        aggregate_wl= AggregateWlEnum.MAX,\n",
                "        threshold=0.5,\n",
                "        weighing=WeighingEnum.LENGTH,\n",
                "        calculate_route_without_disruption=True,\n",
                "        save_gpkg=True,\n",
                "        save_csv=True,\n",
                "    )\n",
                "\n",
                "    _analysis_config_data = AnalysisConfigData(\n",
                "        project=ProjectSection(name=hazard_file.stem),\n",
                "        root_path=_root_dir,\n",
                "        static_path=_static_path,\n",
                "        output_path=_output_path,\n",
                "        analyses=[_analysis_section],        \n",
                "    )\n",
                "    _analysis_config_wrapper = AnalysisConfigWrapper()\n",
                "    _analysis_config_wrapper.config_data = _analysis_config_data\n",
                "    _analysis_config_data.hazard_names = HazardNames.from_config(_analysis_config_wrapper)\n",
                "    \n",
                "\n",
                "    # Add the generated graphs\n",
                "    _graph_files = GraphFilesCollection(\n",
                "        base_graph=GraphFile(\n",
                "            name=\"base_graph\",\n",
                "            folder=_base_graph_dir,\n",
                "            graph=read_pickle(_base_graph_dir / \"base_graph.p\"),\n",
                "            ),\n",
                "        base_network=NetworkFile(\n",
                "            name=\"base_network\",\n",
                "            folder=_base_graph_dir,\n",
                "            graph=read_gpkg_to_gdf(_base_graph_dir / \"base_network.gpkg\"),\n",
                "            ),\n",
                "        origins_destinations_graph=GraphFile(\n",
                "            name=\"origins_destinations_graph\",\n",
                "            folder=_base_graph_dir,\n",
                "            graph=read_pickle(_base_graph_dir / \"origins_destinations_graph.p\"),\n",
                "            ),\n",
                "    )\n",
                "    _handler = Ra2ceHandler.from_config(_network_config_data, _analysis_config_data)\n",
                "    \n",
                "    # Run analysis\n",
                "    _handler.input_config.network_config.graph_files = _graph_files\n",
                "    _handler.configure()\n",
                "    _handler.run_analysis()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.13"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}

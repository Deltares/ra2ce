apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  namespace: argo
  generateName: ra2ce-uncertainty-uq1-
spec:
  entrypoint: scenario-workflow
  templates:
  - name: scenario-workflow
    steps:
    - - name: check-ra2ce
        template: check-ra2ce
        arguments:
          parameters:
          - name: ra2ce_tag
            value: hackathon_uncertainty_pypi
      - name: define-events
        template: get-events
    - - name: run-scenario
        template: run-scenario
        arguments:
          parameters:
          - name: ra2ce_tag
            value: hackathon_uncertainty_pypi
          - name: event_floodmap
            value: "{{item}}"
        withParam: "{{steps.define-events.outputs.result}}"
  - name: check-ra2ce
    script:
      image: "containers.deltares.nl/ra2ce/ra2ce:{{inputs.parameters.ra2ce_tag}}"
      command: [python, "/scripts/check_ra2ce_version.py"]
    inputs: 
      parameters:
        - name: ra2ce_tag
          # value: "{{workflow.parameters.ra2ce_tag}}"
      artifacts:
        - name: scripts
          path: /scripts
          s3:
            endpoint: s3.amazonaws.com
            bucket: ra2ce-data
            key: uncertainty_hackathon/scripts
            region: eu-west-1
            accessKeySecret:
              name: my-s3-credentials
              key: accessKey
            secretKeySecret:
              name: my-s3-credentials
              key: secretKey
          archive:
            none: {}
  - name: get-events
    script:
      image: 798877697266.dkr.ecr.eu-west-1.amazonaws.com/boto3:latest
      workingDir: /modeldata
      command: [python]
      source: |
          import json
          from pathlib import Path
          import boto3

          # s3://ra2ce-data/uncertainty_hackathon/flood_maps/
          bucket = "ra2ce-data"
          _root_dir = "uncertainty_hackathon/flood_maps/"
          
          client = boto3.client("s3")
          result = client.list_objects(Bucket=bucket, Prefix=_root_dir, Delimiter="/")
          members = []
          for _sub_prefix in result.get("CommonPrefixes"):
              _prefix = _sub_prefix["Prefix"]
              _prefix_path = Path(_prefix)
              _prefix_result = client.list_objects(Bucket=bucket, Prefix=_prefix, Delimiter="/")
              _event_files = [
                  str(Path(_c["Key"]).relative_to(_prefix_path.parent))
                  for _c in _prefix_result.get("Contents")
              ]
              members.extend(_event_files)
          print(json.dumps(members))
  - name: run-scenario
    container:
      image: "containers.deltares.nl/ra2ce/ra2ce:{{inputs.parameters.ra2ce_tag}}"
      command: [python, "/scripts/workflow_hazard_overlay.py"]
      resources:
        requests:
          cpu: 1
          memory: "4Gi"
        limits:
          cpu: 1
          memory: "4Gi"
    nodeSelector:
      beta.kubernetes.io/instance-type: "m5.xlarge"
    inputs:
      parameters:
        - name: ra2ce_tag
        - name: event_floodmap
      artifacts:
        - name: events
          path: /events/{{inputs.parameters.event_floodmap}} # How we mount it.
          s3:
            endpoint: s3.amazonaws.com
            bucket: ra2ce-data
            key: "uncertainty_hackathon/flood_maps/{{inputs.parameters.event_floodmap}}"
            region: eu-west-1
            accessKeySecret:
              name: my-s3-credentials
              key: accessKey
            secretKeySecret:
              name: my-s3-credentials
              key: secretKey
          archive:
            none: {}
        - name: modeldata
          path: /modeldata # How we mount it.
          s3:
            endpoint: s3.amazonaws.com
            bucket: ra2ce-data
            key: uncertainty_hackathon/working_dir
            region: eu-west-1
            accessKeySecret:
              name: my-s3-credentials
              key: accessKey
            secretKeySecret:
              name: my-s3-credentials
              key: secretKey
          archive:
            none: {}
        - name: scripts
          path: /scripts
          s3:
            endpoint: s3.amazonaws.com
            bucket: ra2ce-data
            key: uncertainty_hackathon/scripts
            region: eu-west-1
            accessKeySecret:
              name: my-s3-credentials
              key: accessKey
            secretKeySecret:
              name: my-s3-credentials
              key: secretKey
          archive:
            none: {}
    outputs:
      artifacts:
      - name: ra2ce-analysis-output
        path: /output_workflow1/events
        s3:
          bucket: ra2ce-data
          endpoint: s3.amazonaws.com
          region: eu-west-1
          key: uncertainty_hackathon/output_1/
          accessKeySecret:
            name: my-s3-credentials
            key: accessKey
          secretKeySecret:
            name: my-s3-credentials
            key: secretKey
        archive:
          none: {}